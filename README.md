# Statistics-for-Data-Science

## Introduction to Statistics

Statistics is the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data.

### Types of Statistics
1. Descriptive Statistics
2. Inferential Statistics

### Population adn Sample in Statistics
1. Population is the entire group that you wish to draw data from (and subsequently draw conclusions about).
2. Sample is a representative group of a larger population. 

### Data Types in Statistics
1. Categorical
- Nominal Level - Only labels data in different categories, example categorizing as : Male or Female
- Ordinal Level - Data can be arranged and ordered but difference doesnt make sense, for example: ranking as 1st, second and 3rd.

2. Numerical
a. First division:
- Interval Level - Data can be ordered as well as differences can be taken, but multiplication/division is not possible. for example: categorizing as different years like 2011, 2012 etc
- Ratio Level - Ordering, difference and multiplication/division - all operations are possible. For example: Age in years, temperature in degrees etc.

b. Second division:
- Discrete Variable - the variable can only take point values and no values in between. For example: Number of people in a bus.
- Continuous Variable - the variable can take any value within an interval, for example height of a person.

## Probability

Probability is the branch of mathematics concerning numerical descriptions of how likely an event is to occur, or how likely it is that a proposition is true.

## Descriptive Statistic ##
- Distribution

Distribution describes how values are distributed for a field. In other words, the statistical distribution shows which values are common and uncommon

- Skewness

Measure of the asymmetry of a distribution. A distribution is asymmetrical when its left and right side are not mirror images. A distribution can have right (or positive), left (or negative), or zero skewness. A right-skewed distribution is longer on the right side of its peak, and a left-skewed distribution is longer on the left side of its peak

- Correlation Coefficient

Correlation is a statistical measure that expresses the extent to which two variables are linearly related (meaning they change together at a constant rate). It’s a common tool for describing simple relationships without making a statement about cause and effect


## Outliers ##

- Difference Outliers & Anomalies

Outliers are observations that are distant from the mean or location of a distribution. However, they don’t necessarily represent abnormal behavior or behavior generated by a different process. On the other hand, anomalies are data patterns that are generated by different processes or wrong input.

- Example Outliers & Anomalies

Outliers:
When data has an average age of 28 years. However, the data has value grandfather is 70 years old and the baby is 1 year old. Data with numbers 70 and 1 are Outliers values. Because it is beyond average.

Anomalies:
If a data input enters a person's age of -20 or 10,000 years, it can be called an anomaly. Because it doesn't make sense that age is minus 10,000 years.

- How to check Outliers & Anomalies

Anomalies:
We can use the `describe()` function in Python. Then, we look at the maximum and minimum values. If there is something absurd in that value, it is called anomalies.

Outliers:
There are two ways to check outlier values:

a. Boxplot Diagram
Insert a boxplot diagram using the seaborn library. We can use syntax `sns.boxplot();`

b. Use IQR
Steps check outliers use IQR:
1. Choose the data to be checked for outliers
2. Finding first quartile and third quartile
3. Finding the IQR which is the difference between third and first quartile
4. Find lower and upper bound
5. Values below lower bound and above upper bound are outliers.

- Handling Outliers 

To handle outliers, we can select data above the lower bound and below the upper bound. In this way, outlier data will delete.


## Handling Missing Values ##

Before handling missing values, we need to determine the type of data to handle. Including numerical or categorical.
After this, we can choose way to handling missing values:

a. If numerical :
We can use median values ( Curtois or Skewness Distribution )

b. If categorical:
We can use mean values ( Normal Distribution )


## Inferential Statistics ##
Inferential statistics help you come to conclusions and make predictions based on your data.

When you have collected data from a sample, you can use inferential statistics to understand the larger population from which the sample is taken.

Inferential statistics have two main uses:
* making estimates about populations (for example, the mean SAT score of all 11th graders in the US).
* testing hypotheses to draw conclusions about populations (for example, the relationship between SAT scores and family income).


### Confidence Interval ###
In frequentist statistics, a confidence interval (CI) is a range of estimates for an unknown parameter. A confidence interval is computed at a designated confidence level; the 95% confidence level is most common, but other levels, such as 90% or 99%, are sometimes used

### Hypothesis Testing ###
Hypothesis testing is an act in statistics whereby an analyst tests an assumption regarding a population parameter. The methodology employed by the analyst depends on the nature of the data used and the reason for the analysis.

Hypothesis testing is used to assess the plausibility of a hypothesis by using sample data. Such data may come from a larger population, or from a data-generating process. The word "population" will be used for both of these cases in the following descriptions.

**Two Tailed Test**
A two-tailed test, in statistics, is a method in which the critical area of a distribution is two-sided and tests whether a sample is greater than or less than a certain range of values. It is used in null-hypothesis testing and testing for statistical significance. If the sample being tested falls into either of the critical areas, the alternative hypothesis is accepted instead of the null hypothesis.

On two tailed Test, there are two kind of test. First, T-test refers to a univariate hypothesis test based on t-statistic, wherein the mean is known, and population variance is approximated from the sample. On the other hand, Z-test is also a univariate test that is based on standard normal distribution.

Different between Z-test and T-test :
| BASIS FOR COMPARISON      | T-TEST         |Z-TEST    |
| ------------- |:-------------| :-----|
| Meaning      | T-test refers to a type of parametric test that is applied to identify, how the means of two sets of data differ from one another when variance is not given. | Z-test implies a hypothesis test which ascertains if the means of two datasets are different from each other when variance is given.|
| Based on      | Student-t distribution     |   Normal distribution |
| Population variance | Unknown      |    Known |
|Sample Size | Small | Large |
